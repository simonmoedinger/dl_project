{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T21:58:02.144145100Z",
     "start_time": "2023-12-06T21:57:59.568424700Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smoeding2/.conda/envs/dl/lib/python3.11/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/smoeding2/.conda/envs/dl/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/smoeding2/caches/'\n",
    "os.environ['XDG_CACHE_HOME'] = '/home/smoeding2/caches/'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'trained_on_chunk'\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
    "import bitsandbytes\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os, torch, wandb\n",
    "import datasets\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805baf0d880bfd33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T21:58:02.144145100Z",
     "start_time": "2023-12-06T21:58:02.141145Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = \"saved_models/trained_on_chunk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336cb5dfab33f395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T21:58:12.457843300Z",
     "start_time": "2023-12-06T21:58:03.850515400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ac88610a54476fb5c1f31bf122aecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be013bd661a474eba0759f14d4893e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smoeding2/.conda/envs/dl/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load base model(Mistral 7B)\n",
    "bnb_config = BitsAndBytesConfig(  \n",
    "    load_in_4bit= True,\n",
    "#    bnb_4bit_quant_type= \"nf4\",\n",
    "#    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "#    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "#        load_in_4bit=True,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    ")\n",
    "#model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "#model.config.pretraining_tp = 1\n",
    "#model.gradient_checkpointing_enable()\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.add_bos_token, tokenizer.add_eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccef22154fc05fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T21:58:17.946694200Z",
     "start_time": "2023-12-06T21:58:16.973184100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding the adapters in the layers\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_dropout=0.4\n",
    "#    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939e92febdd90f74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T21:58:20.539694500Z",
     "start_time": "2023-12-06T21:58:20.536694400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=10,\n",
    "    gradient_accumulation_steps=10,\n",
    "    gradient_checkpointing=True,\n",
    "    learning_rate=2.0e-5,\n",
    "    logging_steps=1,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=-1,\n",
    "    report_to=\"wandb\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=10,\n",
    "    bf16=False,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    do_eval=False,\n",
    "    evaluation_strategy=\"no\",\n",
    "    logging_first_step=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d709428ae14500ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:53:57.175220100Z",
     "start_time": "2023-12-06T22:27:38.218880400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 12467\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "ds = datasets.load_dataset(\"text\", data_dir=\"../data/instruct_dataset\", split=\"train\")\n",
    "ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "871235823e88e3ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:23:36.429321500Z",
     "start_time": "2023-12-06T22:23:36.386321300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Du bist ein hilfreicher Assistent, der alle Fragen so korrekt wie möglich beantwortet. <BENUTZER>: Es wird eine Frage gestellt, die zwischen den TAGS BEGINFRAGE und ENDFRAGE steht. Die Antwortmöglichkeiten stehen jeweils zwischen den Tags BEGINANTWORT und ENDANTWORT. BEGINFALL <INSERTFALL> ENDFALL BEGINFRAGE Welche Veränderung gegenüber dem Zustand vor der Schwangerschaft tritt im mütterlichen Organismus als typische Anpassung an eine bestehende Schwangerschaft auf? ENDFRAGE BEGINANTWORT  verminderte glomeruläre Filtrationsrate ENDANTWORT BEGINANTWORT  verminderte renale Glucoseausscheidung ENDANTWORT BEGINANTWORT  verminderter arterieller CO2-Partialdruck ENDANTWORT BEGINANTWORT  vermindertes Blutvolumen ENDANTWORT BEGINANTWORT  vermindertes Herzzeitvolumen in Ruhe ENDANTWORT. Beantworte die Frage, indem du die korrekte Antwortmöglichkeit wiedergibst. <ASSISTENT>: BEGINANTWORT 2) verminderter arterieller CO2-Partialdruck ENDANTWORT'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4020bb545abf32a2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    max_seq_length= 1024,\n",
    "    train_dataset=ds,\n",
    "    dataset_text_field=\"text\",\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    packing= True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27660f5fa5541e9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find trained_on_chunk.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjmettner\u001B[0m (\u001B[33mgmllm\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/smoeding2/leolm/wandb/run-20231221_142026-k83sk9zy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gmllm/huggingface/runs/k83sk9zy' target=\"_blank\">iconic-meadow-71</a></strong> to <a href='https://wandb.ai/gmllm/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gmllm/huggingface' target=\"_blank\">https://wandb.ai/gmllm/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gmllm/huggingface/runs/k83sk9zy' target=\"_blank\">https://wandb.ai/gmllm/huggingface/runs/k83sk9zy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/smoeding2/.conda/envs/dl/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 51/124 8:04:23 < 12:01:38, 0.00 it/s, Epoch 0.40/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b53d80-625c-4219-9302-6ba4a9943699",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"saved_models/trained_on_chunk_instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804f25c1f8d032c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "wandb.finish()\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a0a29-08cb-41df-a866-ef690f4cede5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
