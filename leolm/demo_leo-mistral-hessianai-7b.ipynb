{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae7c534-0fb2-432b-a983-0e02f0c9550b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:38.084535400Z",
     "start_time": "2024-01-13T14:30:38.065536300Z"
    }
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['TRANSFORMERS_CACHE'] = '/home/smoeding/caches/'\n",
    "#os.environ['XDG_CACHE_HOME'] = '/home/smoeding/caches/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842dd5ff-83c7-436f-a6d2-0f5c44f5c914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:39.872505200Z",
     "start_time": "2024-01-13T14:30:38.068536100Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, GenerationConfig\n",
    "import torch\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436a4dfae4bac7dc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:54.692812900Z",
     "start_time": "2024-01-13T14:30:39.869506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26ed9651b1974ffab2b5bc7b5d725887"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "#model_name = \"fully_trained_model/\"\n",
    "#model_name = \"trained_on_chunk/\"\n",
    "model_name = \"medalpaca/medalpaca-7b\"\n",
    "#model_name = \"LeoLM/leo-mistral-hessianai-7b\"\n",
    "#model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a5be9de6fa057f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:54.976457700Z",
     "start_time": "2024-01-13T14:30:54.698812900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": "(True, False)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = False\n",
    "tokenizer.add_bos_token, tokenizer.add_eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6be9cb7c17832f8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:54.982459200Z",
     "start_time": "2024-01-13T14:30:54.978458100Z"
    }
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(max_new_tokens=50,\n",
    "                                    temperature=0.4,\n",
    "                                    top_p=0.95,\n",
    "                                    top_k=40,\n",
    "                                    repetition_penalty=1.3,\n",
    "                                    bos_token_id=tokenizer.bos_token_id,\n",
    "                                    eos_token_id=tokenizer.eos_token_id,\n",
    "                                    do_sample=True,\n",
    "                                    use_cache=True,\n",
    "                                    output_attentions=False,\n",
    "                                    output_hidden_states=False,\n",
    "                                    output_scores=False,\n",
    "                                    remove_invalid_values=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ff80a7a740d601",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:54.990458200Z",
     "start_time": "2024-01-13T14:30:54.980457500Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_case = \"Es folgt eine Fallbeschreibung, dessen Anfang und Ende durch die Tags BEGINFALL und ENDFALL markiert ist. Darauf wird eine Frage gestellt, die zwischen den TAGS BEGINFRAGE und ENDFRAGE steht. Antwortmöglichkeiten stehen jeweils zwischen den Tags BEGINANTWORT und ENDANTWORT. BEGINFALL <INSERTFALL> ENDFALL BEGINFRAGE <INSERTFRAGE> ENDFRAGE BEGINANTWORT <INSERTANTWORT0> ENDANTWORT BEGINANTWORT <INSERTANTWORT1> ENDANTWORT BEGINANTWORT <INSERTANTWORT2> ENDANTWORT BEGINANTWORT <INSERTANTWORT3> ENDANTWORT BEGINANTWORT <INSERTANTWORT4> ENDANTWORT. Beantworte die Frage, indem du die korrekte Antwortmöglichkeit wiedergibst. Die richtige Antwort ist: BEGINANTWORT\"\n",
    "prompt_few_shots = \"\"\"Es folgt eine Fallbeschreibung, dessen Anfang und Ende durch die Tags BEGINFALL und ENDFALL markiert ist. Darauf wird eine Frage gestellt, die zwischen den TAGS BEGINFRAGE und ENDFRAGE steht. Die Antwortmöglichkeiten stehen jeweils zwischen den Tags BEGINANTWORT und ENDANTWORT. BEGINFALL Ein 3 Tage altes männliches Neugeborenes wird mit zunehmender Somnolenz, Apathie, Erbrechen, erhöhter Atemfrequenz und epileptischem Anfall auf die pädiatrische Intensivstation aufgenommen. ENDFALL BEGINFRAGE Welcher der folgenden Laborparameter ist im Sinne einer raschen Diagnosefindung am wenigsten dringlich zu bestimmen? ENDFRAGE BEGINANTWORT 0) Laktat ENDANTWORT BEGINANTWORT 1) Glukose ENDANTWORT BEGINANTWORT 2) Ammoniak ENDANTWORT BEGINANTWORT 3) C-reaktives Protein ENDANTWORT BEGINANTWORT 4) Harnsäure ENDANTWORT. Beantworte die Frage, indem du die korrekte Antwortmöglichkeit wiedergibst. Die richtige Antwort ist: BEGINANTWORT 4) Harnsäure ENDANTWORT.\n",
    "Es folgt eine Fallbeschreibung, dessen Anfang und Ende durch die Tags BEGINFALL und ENDFALL markiert ist. Darauf wird eine Frage gestellt, die zwischen den TAGS BEGINFRAGE und ENDFRAGE steht. Die Antwortmöglichkeiten stehen jeweils zwischen den Tags BEGINANTWORT und ENDANTWORT. BEGINFALL Ein 19-jähriger Patient stellt sich bei Ihnen in der dermatologischen Sprechstunde vor, weil er seit einigen Jahren an einer Akne im Gesicht leide. Die Haut erscheine immer fettig und glänze häufig. Die Akne sei nun in den letzten 3-4 Monaten sehr viel schlimmer geworden und er wache morgens öfters auf einem blutigen Kopfkissen auf. Wenn neue Hauterscheinungen entstehen, dann sei dies gelegentlich auch sehr schmerzhaft.Am Vorabend habe er einen Pickel auf dem Nasenrücken, der ihn gestört habe, manuell entfernen wollen; jetzt sei es zu einer starken Schwellung im Augeninnenwinkel gekommen. Die ganze Region sei schmerzhaft.<br>Seine Mutter habe auch an Akne gelitten, der Vater nicht. Seine Schwester sei erst 12 Jahre alt, und bisher sei bei ihr keine Akne aufgetreten. Allergien habe er nicht. Weitere Grunderkrankungen sind nicht bekannt. Auf Nachfrage verneint der Patient eine Medikamenteneinnahme.Klinisch zeigen sich typische Akneeffloreszenzen, auch mit kleinen Knoten. Dazu findet sich an beiden Wangen und im Kinnbereich eine Vielzahl von zum Teil eingezogenen Narben. Im Bereich des Augeninnenwinkels links zeigt sich eine im Durchmesser ca. 2 cm große, hellrote Schwellung mit zentralem Eiter. Andere Körperregionen sind weniger betroffen, einzelne Hautveränderungen finden sich auch an beiden Schultern. Neurologische Störungen stellen sich nicht dar.<br>In den Laboruntersuchungen zeigt sich ein deutlich erhöhtes C-reaktives Protein (75 mg/L), das Blutbild ist unauffällig. Ein HIV-Test ist negativ. Eine Sinus-cavernosus-Thrombose kann bei dem jungen Mann ausgeschlossen werden. Sie informieren den Patienten über die Erkrankung, deren Ursachen und den Verlauf und besprechen das weitere therapeutische Vorgehen. Wegen des beginnenden Abszesses im inneren Augenwinkel veranlassen Sie zunächst eine orale Antibiotikatherapie mit Clindamycin für mehrere Tage. Hierunter kommt es innerhalb von 3 Tagen zu einer zügigen Rückbildung des Abszesses und der Schmerzen im Augenwinkel, das CRP ist nach 7 Tagen innerhalb des Referenzbereiches. Die Clindamycintherapie wird beendet. Anschließend empfehlen Sie dem Patienten eine Kombinationstherapie, die er für mehrere Wochen anwenden soll. Auch eine milde Reinigung der Haut mit pH-neutralen Waschsyndets wird empfohlen. Eine Kontrolluntersuchung in 8 Wochen wird vereinbart. ENDFALL BEGINFRAGE Welche der folgenden Kombinationen von Hautveränderungen liegt bei diesem Patienten am wahrscheinlichsten vor? ENDFRAGE BEGINANTWORT 0) Bläschen, Krusten ENDANTWORT BEGINANTWORT 1) Komedonen, Papeln ENDANTWORT BEGINANTWORT 2) Petechien, Schuppen ENDANTWORT BEGINANTWORT 3) Rhagaden, Quaddeln ENDANTWORT BEGINANTWORT 4) Quaddeln, Bläschen ENDANTWORT. Beantworte die Frage, indem du die korrekte Antwortmöglichkeit wiedergibst. Die richtige Antwort ist: BEGINANTWORT 1) Komedonen, Papeln ENDANTWORT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def prompt_model(prompt):\n",
    "    input_tokens=tokenizer(prompt_few_shots + prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output_tokens=model.generate(**input_tokens, generation_config=generation_config, pad_token_id=tokenizer.eos_token_id)[0]\n",
    "    answer=tokenizer.decode(output_tokens, skip_special_tokens=True)\n",
    "    return answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:55.028457900Z",
     "start_time": "2024-01-13T14:30:54.991459Z"
    }
   },
   "id": "888ecf4e24eaee86"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee5cfd96cc34947",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:55.032458200Z",
     "start_time": "2024-01-13T14:30:55.001457700Z"
    }
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\"../output.csv\")\n",
    "questions_df[\"Prediction LLM\"] = [-1 for i in range(len(questions_df))]\n",
    "questions_df[\"Answer LLM\"] = [-1 for i in range(len(questions_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:30:55.033309400Z",
     "start_time": "2024-01-13T14:30:55.024457400Z"
    }
   },
   "id": "45cd0ef604feb0d2"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aba98c46cd6efe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:45:37.729293Z",
     "start_time": "2024-01-13T14:42:59.559565600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [02:38,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values set: 124 / 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import difflib\n",
    "\n",
    "for index, row in tqdm(questions_df.iterrows()):\n",
    "    if row[\"Answer LLM\"] == -1:\n",
    "        if type(row[\"Case\"]) == str:\n",
    "            prompt = prompt_case.replace(\"<INSERTFALL>\",row[\"Case\"])\n",
    "        else:\n",
    "            prompt = prompt_case.replace(\"<INSERTFALL>\", \"\")\n",
    "        prompt = prompt.replace(\"<INSERTFRAGE>\",row[\"Question\"])\n",
    "        for i in range(5):\n",
    "            prompt = prompt.replace(\"<INSERTANTWORT\" + str(i) + \">\",row[\"Answer \"+ str(i+1)])\n",
    "        answer = prompt_model(prompt).split(\"Die richtige Antwort ist: BEGINANTWORT\")\n",
    "        answer = answer[len(answer)-1].split(\"ENDANTWORT\")[0]\n",
    "        found = False\n",
    "        for i in range(5):\n",
    "            if row[\"Answer \"+ str(i+1)].strip().lower().replace(\".\",\"\").replace(\"\\n\",\"\") == answer.strip().lower().replace(\".\",\"\").replace(\"\\n\",\"\"):\n",
    "                found = i\n",
    "                break\n",
    "                \n",
    "        #print(answer)\n",
    "        \n",
    "        \n",
    "        if found != False:\n",
    "            questions_df.loc[index, \"Answer LLM\"] = found\n",
    "        questions_df.loc[index, \"Prediction LLM\"] = answer\n",
    "print(\"Values set:\", len(questions_df[questions_df[\"Answer LLM\"] != -1]),\"/\",len(questions_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5194e3f9c58349c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:45:49.760717900Z",
     "start_time": "2024-01-13T14:45:49.752595Z"
    }
   },
   "outputs": [],
   "source": [
    "questions_df.to_csv(\"medalpaca_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed43cb16ba034b9b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:35:43.387100400Z",
     "start_time": "2024-01-13T14:35:43.383097800Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = questions_df[questions_df[\"Answer LLM\"] != -1][\"Answer LLM\"]\n",
    "y_true = questions_df[questions_df[\"Answer LLM\"] != -1][\"Correct Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a6ec3d09c98719",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T14:35:43.426097300Z",
     "start_time": "2024-01-13T14:35:43.384100300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14814814814814814\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
