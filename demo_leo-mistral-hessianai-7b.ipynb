{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae7c534-0fb2-432b-a983-0e02f0c9550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/smoeding/caches/'\n",
    "os.environ['XDG_CACHE_HOME'] = '/home/smoeding/caches/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842dd5ff-83c7-436f-a6d2-0f5c44f5c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smoeding/.local/lib/python3.9/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, GenerationConfig\n",
    "import torch\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436a4dfae4bac7dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T08:56:39.704999500Z",
     "start_time": "2023-11-24T08:56:23.049139300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390b479e90cc473280de29d4ec2798f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"LeoLM/leo-mistral-hessianai-7b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a5be9de6fa057f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T08:56:39.870338700Z",
     "start_time": "2023-11-24T08:56:39.700985500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id=tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6be9cb7c17832f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T08:56:39.875651200Z",
     "start_time": "2023-11-24T08:56:39.870338700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generation_config=GenerationConfig(max_new_tokens=30,\n",
    "                                    temperature=0.4,\n",
    "                                    top_p=0.95,\n",
    "                                    top_k=40,\n",
    "                                    repetition_penalty=1.2,\n",
    "                                    bos_token_id=tokenizer.bos_token_id,\n",
    "                                    eos_token_id=tokenizer.eos_token_id,\n",
    "                                    do_sample=True,\n",
    "                                    use_cache=True,\n",
    "                                    output_attentions=False,\n",
    "                                    output_hidden_states=False,\n",
    "                                    output_scores=False,\n",
    "                                    remove_invalid_values=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e996c8ae797740a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T08:56:39.879855700Z",
     "start_time": "2023-11-24T08:56:39.873644400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def prompt_model(prompt):\n",
    "    input_tokens=tokenizer(prompt + \" Die richtige Antwort ist BEGINANTWORT\", return_tensors=\"pt\").to(model.device)\n",
    "    output_tokens=model.generate(**input_tokens, generation_config=generation_config, pad_token_id=tokenizer.eos_token_id)[0]\n",
    "    answer=tokenizer.decode(output_tokens, skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ff80a7a740d601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T08:56:39.885267200Z",
     "start_time": "2023-11-24T08:56:39.878852100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    " = \"Es folgt eine Fallbeschreibung, dessen Anfang und Ende durch die Tags BEGINFALL und ENDFALL markiert ist. Darauf wird eine Frage gestellt, die zwischen den TAGS BEGINFRAGE und ENDFRAGE steht. Antwortmöglichkeiten stehen jeweils zwischen den Tags BEGINANTWORT und ENDANTWORT. BEGINFALL <INSERTFALL> ENDFALL BEGINFRAGE <INSERTFRAGE> ENDFRAGE BEGINANTWORT <INSERTANTWORT0> ENDANTWORT BEGINANTWORT <INSERTANTWORT1> ENDANTWORT BEGINANTWORT <INSERTANTWORT2> ENDANTWORT BEGINANTWORT <INSERTANTWORT3> ENDANTWORT BEGINANTWORT <INSERTANTWORT4> ENDANTWORT. Die Frage wird gleich dadurch Beantwortet, die korrekte Antwortmöglichkeit wortwörtlich wiederzugeben.\"\n",
    "prompt_no_case = \"Es prompt_casewird eine Frage gestellt, die zwischen den TAGS BEGINFRAGE und ENDFRAGE steht. Antwortmöglichkeiten stehen jeweils zwischen den Tags BEGINANTWORT und ENDANTWORT. BEGINFALL <INSERTFALL> ENDFALL BEGINFRAGE <INSERTFRAGE> ENDFRAGE BEGINANTWORT <INSERTANTWORT0> ENDANTWORT BEGINANTWORT <INSERTANTWORT1> ENDANTWORT BEGINANTWORT <INSERTANTWORT2> ENDANTWORT BEGINANTWORT <INSERTANTWORT3> ENDANTWORT BEGINANTWORT <INSERTANTWORT4> ENDANTWORT. Die Frage wird gleich dadurch Beantwortet, die korrekte Antwortmöglichkeit wortwörtlich wiederzugeben.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee5cfd96cc34947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T08:56:40.307731400Z",
     "start_time": "2023-11-24T08:56:40.292352700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\"output.csv\")\n",
    "questions_df[\"Answer LLM\"] = [-1 for i in range(len(questions_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aba98c46cd6efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:12:17.627536Z",
     "start_time": "2023-11-24T09:10:23.737879900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values set: 144 / 248\n"
     ]
    }
   ],
   "source": [
    "for index, row in questions_df.iterrows():\n",
    "    if row[\"Answer LLM\"] == -1:\n",
    "        if type(row[\"Case\"]) == str:\n",
    "            prompt = prompt_case.replace(\"<INSERTFALL>\",row[\"Case\"])\n",
    "        else:\n",
    "            prompt = prompt_no_case\n",
    "        prompt = prompt.replace(\"<INSERTFRAGE>\",row[\"Question\"])\n",
    "        for i in range(5):\n",
    "            prompt = prompt.replace(\"<INSERTANTWORT\" + str(i) + \">\",row[\"Answer \"+ str(i+1)].replace(str(i) + \")\",\"\"))\n",
    "        answer = prompt_model(prompt).split(\"Die richtige Antwort ist BEGINANTWORT\")[1].split(\"ENDANTWORT\")[0]\n",
    "        found = False\n",
    "        for i in range(5):\n",
    "            if row[\"Answer \"+ str(i+1)].replace(str(i) + \")\",\"\").strip().lower() == answer.strip().lower():\n",
    "                found = i\n",
    "                break\n",
    "        #print(answer)\n",
    "        if found != False:\n",
    "            questions_df.loc[index, \"Answer LLM\"] = found\n",
    "print(\"Values set:\", len(questions_df[questions_df[\"Answer LLM\"] != -1]),\"/\",len(questions_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5194e3f9c58349c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:13:35.673403Z",
     "start_time": "2023-11-24T09:13:35.666689300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "questions_df.to_csv(\"leo_mistral_hessiani_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed43cb16ba034b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:12:46.483444Z",
     "start_time": "2023-11-24T09:12:46.478481300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = questions_df[questions_df[\"Answer LLM\"] != -1][\"Answer LLM\"]\n",
    "y_true = questions_df[questions_df[\"Answer LLM\"] != -1][\"Correct Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67a6ec3d09c98719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T09:13:10.402273900Z",
     "start_time": "2023-11-24T09:13:10.398224300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3680555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
